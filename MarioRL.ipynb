{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b618e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym-super-mario-bros\n",
      "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
      "\u001b[K     |████████████████████████████████| 199 kB 706 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nes-py>=8.1.4\n",
      "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gym>=0.17.2 in /home/sakib/.local/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/sakib/.local/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.19.5)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /home/sakib/.local/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /home/sakib/.local/lib/python3.8/site-packages (from nes-py>=8.1.4->gym-super-mario-bros) (4.64.0)\n",
      "Requirement already satisfied: scipy in /home/sakib/.local/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.8.1)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in /usr/lib/python3/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (7.0.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/sakib/.local/lib/python3.8/site-packages (from gym>=0.17.2->nes-py>=8.1.4->gym-super-mario-bros) (1.6.0)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from pyglet<=1.5.21,>=1.4.0->nes-py>=8.1.4->gym-super-mario-bros) (0.18.2)\n",
      "Building wheels for collected packages: nes-py\n",
      "  Building wheel for nes-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nes-py: filename=nes_py-8.2.1-cp38-cp38-linux_x86_64.whl size=497197 sha256=8507ce6b2c91157953bde54aa84d55c73bbc2d8fcb6ea9c1fc49a0b4e0719098\n",
      "  Stored in directory: /home/sakib/.cache/pip/wheels/17/e5/5c/8dfae61b44dbf56c458483aa09accef55a650e0527f6cbd872\n",
      "Successfully built nes-py\n",
      "Installing collected packages: nes-py, gym-super-mario-bros\n",
      "Successfully installed gym-super-mario-bros-7.4.0 nes-py-8.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install gym-super-mario-bros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48fd460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies for mario\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94a4d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd2b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, RIGHT_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f70468f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      9\u001b[0m state, reward,done,info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample())\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m     13\u001b[0m clear_output(wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/iostream.py:549\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_master_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/ipykernel/iostream.py:436\u001b[0m, in \u001b[0;36mOutStream._is_master_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatch_fd_thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwatch_fd_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_master_process\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_master_pid\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_parent\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_reward = 0\n",
    "done = True\n",
    "\n",
    "for step in range(100000):\n",
    "    env.render()\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        \n",
    "    state, reward,done,info = env.step(env.action_space.sample())\n",
    "    print(info)\n",
    "\n",
    "    total_reward += reward\n",
    "    clear_output(wait = True)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4c4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87bb7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABQCAAAAAC4re2FAAAE+klEQVR4nO2Y224aVxSG/7VnGBiGgcEHDD4lcRzHTmI1UZW2aqJctVJ6lapS3qBXfYW+QtX7Xvc12qtWPSmNncZqkvp84HwyMAwww+zdCww4VgImImoqsYXQz2atj3/WXns0bPoGb2ewt8T9H4LltnAFEQCQIM649PoMDgHGCRASbxvjYJy4IOr6bIPFB6b32MhHm7srJddnbr/2StzlQlRIjl7Pj68vG6l9BgCrgaerZX/FoEKmyM6AL6m2ebxYkTZRX1q/tdmy3/4SJNqf+dQdXvrlnlN1Zx5PJa8lHQJcK5Rl1eWA08iY7bg2mF7kotyyZK+rqjsLz2Wf1fpllwnAx+t6nbdSWCavmXPPPN5M6Hpx7G+bAaAK06TwZn5KDahlOuPYilhCL3r5bNZr19UVfS/FAG7YWytN36ya9yt/tgKl5xzy/R+EUg/rv3paNWaZtK42E5GaZfjLJ8BOLWeqkVh1TudzXL1QmYyYIQ4AQqmHLvoDzpzrk8RJhixJinb14ykEPYy1KTEenq9GYidpAOhk5wlv9CCoHc3UCxfTPHYQ1BIEAOXM3LioTTYKFzNWxwPXo6U02Jzn0OmsBPfppelO2ikwBJe4kFxiLgOXuGg3HLlgLjGXnVpN4TIGuEI6PSfodFq3j0kCA6STV7fbRGe2O0gGzkyB6KW0d2tLv9TjQwRTNYf+6DcAZ8O3042+ZLlfwNlBlYkvZeURKaJ33KCORRIPy/Znn+yX+3ge0LEof35T48D7iSe5iZ6eB3NMmVt3NC4glIdfwekZOhhYGDu7xxY/Ek2Q6H2xA5bCZ37/0fwxy84HyyHe09SgNQ5Uf1x0c1d+zthjUs8aD9puQtMS8D3RDAm9+23gPhbQISZEH+wbgAGBvlS8Y3e3EXgEHoFH4BF4BB6BR+AR+L8Bv/S0yQj8HA+Sg4KZkyl6Yv4hkbtgKf0MWnNj/iYNBd0Bs+TmJAl7Q/1rlQ2D3F48ltwaF7zx20pErDXP8+/+nGAW3x4TgHz1uuKV1odBboHZ4e64AMCiLoTXs+YMRiZqv3XPMlrHW/sH463TJ05EXPE+tgcgE/I1BlYrtGUHLO0ejXH54HcJAFOdn5oeda1x/p3TiEcaeZZ2JuJNJx5p5FueZIBtp8a4tJ9iADyL0UICwkNrN1Xem9f2y47uLR0+2tXuS+zw+NMrh39kIxwAA9tKhTngXvjQBZpu3VqSIGRt3TqXZ7L+uREuhR/47xbtO9dXwqXwF9WUSwB9u5kzOACCADDlqQScDAByK+9p/T1TTdyeBMA9XEAw4gB78TxxWQLbKIwJIiKAiJjPtVyVERE8obUyQOJkH4pXy2bqboyIkSxAjJEgRmL5wUqaSF4MWsmFZIy2Z0zVX9+dHJdJnzZVfy21mlrA1qwZ8FupS6kYvVrmikeqv5ZcSMZoa9ZsyZmptF6m7w4aJgKGHTeyNyo1U+gdiUDQiYdyN8q1qtAN+9UyETiJPZVmNBPhLRkQFFQA7g9KQlCoK4MKIxFwZCIWVOg1kgddryV5gorMWVcKzWC7jj2u7BSaHsPcGaK02XS1qJd0/WDMdKaGKGv0tWXsQVNklnWibnBosiJfyNaMkDXp7i3GI7Y1LLn0QnZNu1iartn1fRtmY1hyr8LKEo9dzjmSfE0pDFH6WSNfCJXrtcOgVbOHKBvMafjiT8lqKBspDE8+3f8Xxqio0H87vtUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=88x80 at 0x7F297D503730>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "preprocess_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2afae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        #create the variables for our agent\n",
    "        self.state_space = state_size\n",
    "        self.action_space = action_size\n",
    "        self.memory = deque(maxlen = 5000)\n",
    "        self.chosenAction = 0\n",
    "        \n",
    "        #hyperparams\n",
    "        self.gamma = 0.8\n",
    "        self.epsilon = 1\n",
    "        self.max_epsilon = 1\n",
    "        self.min_epsilon = 0.01\n",
    "        self.decay_epsilon = 0.0001\n",
    "        \n",
    "        #building neural network for agent\n",
    "        self.main_network = self.build_network()\n",
    "        self.target_network = self.build_network()\n",
    "        self.update_target_network()\n",
    "        \n",
    "    \n",
    "    def build_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (4,4), strides = 4, padding = 'same', input_shape = self.state_space))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2D(16, (3,3), strides = 2, padding = 'same'))\n",
    "        model.add (Activation ('relu'))\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(256, activation = 'relu'))\n",
    "        model.add(Dense(128, activation = 'relu'))\n",
    "        model.add(Dense(self.action_space, activation = 'linear'))\n",
    "        \n",
    "        model.compile(loss = 'mse', optimizer = Adam())\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.main_network.get_weights())\n",
    "    \n",
    "    \n",
    "    def act(self, state, onGround):\n",
    "        \n",
    "        if onGround < 83:\n",
    "            print(\"On Ground\")\n",
    "            if random.uniform(0, 1) < self.epsilon:\n",
    "                self.chosenAction = np.random.randint(self.action_space)\n",
    "                return self.chosenAction\n",
    "\n",
    "            Q_value = self.main_network.predict(state)\n",
    "            self.chosenAction = np.argmax(Q_value[0])\n",
    "            print(Q_value)\n",
    "\n",
    "            return self.chosenAction\n",
    "        else:\n",
    "            print(\"not On Ground\")\n",
    "            return self.chosenAction\n",
    "    def update_epsilon(self, episode):\n",
    "        self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon) * np.exp(-self.decay_epsilon * episode)\n",
    "\n",
    "    \n",
    "    def train(self, batch_size):\n",
    "        # minibatch from memory\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.main_network.predict(state)\n",
    "            \n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "                \n",
    "            else:\n",
    "                target[0][action] = (reward + self.gamma * np.amax(self.target_network.predict(next_state)))\n",
    "                \n",
    "                \n",
    "            self.main_network.fit(state, target, epochs = 1, verbose = 0)\n",
    "            \n",
    "            \n",
    "    def store_transition(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f43fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "state_space = (80,88,1)\n",
    "#env.observation_space\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_state (state):\n",
    "    image = Image.fromarray(state)\n",
    "    image = image.resize((88, 80))\n",
    "    image = image.convert('L')\n",
    "    image = np.array(image)\n",
    "    #image.show()\n",
    "    \n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d1cd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f6581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1000000\n",
    "num_timesteps = 40000\n",
    "batch_size = 64\n",
    "DEBUG_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d04cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-01 18:47:35.287256: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sakib/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-01 18:47:35.287278: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-01 18:47:35.287292: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sakib-MS-7C83): /proc/driver/nvidia/version does not exist\n",
      "2022-07-01 18:47:35.287452: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-01 18:47:35.316743: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3099995000 Hz\n",
      "2022-07-01 18:47:35.317273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b85bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-01 18:47:35.317285: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "dqn = DQNAgent(state_space, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c8e2a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     clear_output(wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dqn\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 53\u001b[0m         \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m dqn\u001b[38;5;241m.\u001b[39mupdate_epsilon(i)\n\u001b[1;32m     57\u001b[0m clear_output(wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     target[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m (reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mamax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_network\u001b[38;5;241m.\u001b[39mpredict(next_state)))\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1049\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1043\u001b[0m   val_x, val_y, val_sample_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1044\u001b[0m       data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[1;32m   1047\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1048\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1049\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1104\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1120\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter\u001b[38;5;241m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:328\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take quite\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# a while so we don't want to wait for prefetching over an epoch boundary to\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# trigger the next permutation. On the other hand, too many simultaneous\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# shuffles can contend on a hardware level and degrade all performance.\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m  This step can be accomplished in several ways. The most natural is to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:1695\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m\"\"\"Maps `map_func` across the elements of this dataset.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03mThis transformation applies `map_func` to each element of this dataset, and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m  Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_parallel_calls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1695\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1697\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   1698\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1699\u001b[0m       map_func,\n\u001b[1;32m   1700\u001b[0m       num_parallel_calls,\n\u001b[1;32m   1701\u001b[0m       deterministic,\n\u001b[1;32m   1702\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4041\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   4040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 4041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4045\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4046\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m   4047\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4048\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4051\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   4052\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_structure)\n\u001b[1;32m   4053\u001b[0m \u001b[38;5;28msuper\u001b[39m(MapDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3371\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3368\u001b[0m resource_tracker \u001b[38;5;241m=\u001b[39m tracking\u001b[38;5;241m.\u001b[39mResourceTracker()\n\u001b[1;32m   3369\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracking\u001b[38;5;241m.\u001b[39mresource_tracker_scope(resource_tracker):\n\u001b[1;32m   3370\u001b[0m   \u001b[38;5;66;03m# TODO(b/141462134): Switch to using garbage collection.\u001b[39;00m\n\u001b[0;32m-> 3371\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m add_to_graph:\n\u001b[1;32m   3373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function\u001b[38;5;241m.\u001b[39madd_to_graph(ops\u001b[38;5;241m.\u001b[39mget_default_graph())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2938\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2932\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2933\u001b[0m \n\u001b[1;32m   2934\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   2935\u001b[0m \u001b[38;5;124;03m    *args: inputs to specialize on.\u001b[39;00m\n\u001b[1;32m   2936\u001b[0m \u001b[38;5;124;03m    **kwargs: inputs to specialize on.\u001b[39;00m\n\u001b[1;32m   2937\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2938\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2939\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2940\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2941\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2906\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2905\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2906\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2907\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   2908\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2909\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3213\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(args, kwargs)\n\u001b[1;32m   3212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3213\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, args, kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3065\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3060\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3061\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3062\u001b[0m ]\n\u001b[1;32m   3063\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3064\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3066\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3067\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3068\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3076\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3077\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3078\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3079\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3080\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3081\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3082\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:912\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    904\u001b[0m func_kwargs \u001b[38;5;241m=\u001b[39m _get_defun_inputs_from_kwargs(\n\u001b[1;32m    905\u001b[0m     kwargs, flat_shapes\u001b[38;5;241m=\u001b[39mkwarg_shapes)\n\u001b[1;32m    907\u001b[0m \u001b[38;5;66;03m# Convert all Tensors into TensorSpecs before saving the structured inputs.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;66;03m# If storing pure concrete functions that are not called through polymorphic\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;66;03m# functions, we don't have access to FunctionSpec, so we need to call the\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;66;03m# TensorSpecs by their `arg_names` for later binding.\u001b[39;00m\n\u001b[1;32m    911\u001b[0m func_graph\u001b[38;5;241m.\u001b[39mstructured_input_signature \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 912\u001b[0m     \u001b[43mconvert_structure_to_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    913\u001b[0m     convert_structure_to_signature(func_kwargs))\n\u001b[1;32m    915\u001b[0m flat_func_args \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(func_args, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m flat_func_kwargs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(func_kwargs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:130\u001b[0m, in \u001b[0;36mconvert_structure_to_signature\u001b[0;34m(structure, arg_names)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[38;5;66;03m# Replace all top-level names with their actual arg_names. If a path before\u001b[39;00m\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;66;03m# was \"(2,'a',1)\", it will become \"(arg_names[2],'a',1)\".\u001b[39;00m\n\u001b[1;32m    126\u001b[0m   flattened \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m       ((arg_names[path[\u001b[38;5;241m0\u001b[39m]],) \u001b[38;5;241m+\u001b[39m path[\u001b[38;5;241m1\u001b[39m:], arg) \u001b[38;5;28;01mfor\u001b[39;00m path, arg \u001b[38;5;129;01min\u001b[39;00m flattened\n\u001b[1;32m    128\u001b[0m   ]\n\u001b[0;32m--> 130\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [encode_arg(arg, path) \u001b[38;5;28;01mfor\u001b[39;00m path, arg \u001b[38;5;129;01min\u001b[39;00m flattened]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(structure, mapped)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:130\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[38;5;66;03m# Replace all top-level names with their actual arg_names. If a path before\u001b[39;00m\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;66;03m# was \"(2,'a',1)\", it will become \"(arg_names[2],'a',1)\".\u001b[39;00m\n\u001b[1;32m    126\u001b[0m   flattened \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    127\u001b[0m       ((arg_names[path[\u001b[38;5;241m0\u001b[39m]],) \u001b[38;5;241m+\u001b[39m path[\u001b[38;5;241m1\u001b[39m:], arg) \u001b[38;5;28;01mfor\u001b[39;00m path, arg \u001b[38;5;129;01min\u001b[39;00m flattened\n\u001b[1;32m    128\u001b[0m   ]\n\u001b[0;32m--> 130\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\u001b[43mencode_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path, arg \u001b[38;5;129;01min\u001b[39;00m flattened]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(structure, mapped)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:88\u001b[0m, in \u001b[0;36mconvert_structure_to_signature.<locals>.encode_arg\u001b[0;34m(arg, path)\u001b[0m\n\u001b[1;32m     85\u001b[0m user_specified_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m   user_specified_name \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_str(\n\u001b[0;32m---> 88\u001b[0m       \u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_user_specified_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2491\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2489\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   2490\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m-> 2491\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mattr_value_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttrValue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2492\u001b[0m x\u001b[38;5;241m.\u001b[39mParseFromString(data)\n\u001b[1;32m   2494\u001b[0m oneof_value \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mWhichOneof(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('starting training')\n",
    "\n",
    "stuck_buffer = deque(maxlen = DEBUG_LENGTH)\n",
    "\n",
    "for i in range (num_episodes):\n",
    "    Return = 0\n",
    "    done = False\n",
    "    time_step = 0\n",
    "    \n",
    "    state = preprocess_state(env.reset())\n",
    "    state = state.reshape(-1, 80, 88, 1)\n",
    "    \n",
    "    onGround = 79\n",
    "    \n",
    "    \n",
    "    for t in range(num_timesteps):\n",
    "        env.render()\n",
    "        time_step += 1\n",
    "        if done:\n",
    "            env.reset()\n",
    "            break\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        if t > 1 and stuck_buffer.count(stuck_buffer[-1]) > DEBUG_LENGTH - 50:\n",
    "            action = dqn.act(state, onGround = 79)\n",
    "        else:\n",
    "            action = dqn.act(state, onGround)\n",
    "        #action = dqn.act(state, onGround)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        \n",
    "        \n",
    "        onGround = info['y_pos']\n",
    "        #time.sleep(0.01)\n",
    "        print(f'ACTION is: {action}')\n",
    "        stuck_buffer.append(info['x_pos'])\n",
    "        \n",
    "        next_state = preprocess_state(next_state)\n",
    "        next_state = next_state.reshape(-1, 80, 88, 1)\n",
    "        \n",
    "        dqn.store_transition(state, action, reward, next_state, done)\n",
    "        \n",
    "        Return += reward\n",
    "        \n",
    "        print(f'Episode: {i}\\nTotal Time Step: {time_step}\\nCurrent Reward: {Return}\\nEpsilon: {dqn.epsilon}')\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        \n",
    "        if len(dqn.memory) > batch_size and i > 1:\n",
    "            dqn.train(batch_size)\n",
    "            \n",
    "        \n",
    "    dqn.update_epsilon(i)\n",
    "    clear_output(wait = True)\n",
    "    dqn.update_target_network()\n",
    "    \n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f75ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
